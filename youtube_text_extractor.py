#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube å½±ç‰‡æ–‡å­—æå–å™¨
æ ¹æ“šæ­¥é©ŸåŒ–æµç¨‹å¾ YouTube å½±ç‰‡ä¸­æå–å’Œè™•ç†æ–‡å­—å…§å®¹
"""

import re
import os
import json
import logging
from typing import List, Dict, Optional, Tuple
from urllib.parse import urlparse, parse_qs
import requests

# éœ€è¦å®‰è£çš„å¥—ä»¶ï¼š
# pip install youtube-transcript-api google-api-python-client

try:
    from youtube_transcript_api import YouTubeTranscriptApi
    from youtube_transcript_api.formatters import TextFormatter
    from googleapiclient.discovery import build
except ImportError as e:
    print(f"è«‹å®‰è£å¿…è¦å¥—ä»¶: pip install youtube-transcript-api google-api-python-client")
    print(f"éŒ¯èª¤è©³æƒ…: {e}")
    exit(1)

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class YouTubeTextExtractor:
    """YouTube å½±ç‰‡æ–‡å­—æå–å™¨ä¸»é¡åˆ¥"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–æå–å™¨
        
        Args:
            api_key: YouTube Data API v3 é‡‘é‘°ï¼ˆå¯é¸ï¼‰
        """
        self.api_key = api_key
        self.youtube_service = None
        
        if api_key:
            try:
                self.youtube_service = build('youtube', 'v3', developerKey=api_key)
                logger.info("YouTube API æœå‹™åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"YouTube API åˆå§‹åŒ–å¤±æ•—: {e}")
    
    def extract_video_id(self, url: str) -> Optional[str]:
        """
        æ­¥é©Ÿ 1: å¾ YouTube URL æå–å½±ç‰‡ ID
        
        Args:
            url: YouTube å½±ç‰‡ URL
            
        Returns:
            å½±ç‰‡ ID æˆ– None
        """
        logger.info(f"æå–å½±ç‰‡ ID: {url}")
        
        # è™•ç†ä¸åŒæ ¼å¼çš„ YouTube URL
        patterns = [
            r'(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/)([^&\n?#]+)',
            r'youtube\.com/v/([^&\n?#]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                video_id = match.group(1)
                logger.info(f"æˆåŠŸæå–å½±ç‰‡ ID: {video_id}")
                return video_id
        
        # ç›´æ¥æª¢æŸ¥æ˜¯å¦å·²ç¶“æ˜¯ video_id
        if re.match(r'^[a-zA-Z0-9_-]{11}$', url):
            logger.info(f"è¼¸å…¥å·²æ˜¯å½±ç‰‡ ID: {url}")
            return url
        
        logger.error(f"ç„¡æ³•å¾ URL æå–å½±ç‰‡ ID: {url}")
        return None
    
    def check_captions_available(self, video_id: str) -> Tuple[bool, List[Dict]]:
        """
        æ­¥é©Ÿ 2: æª¢æŸ¥å½±ç‰‡æ˜¯å¦æœ‰å­—å¹•
        
        Args:
            video_id: YouTube å½±ç‰‡ ID
            
        Returns:
            (æ˜¯å¦æœ‰å­—å¹•, å¯ç”¨å­—å¹•åˆ—è¡¨)
        """
        logger.info(f"æª¢æŸ¥å½±ç‰‡å­—å¹•å¯ç”¨æ€§: {video_id}")
        
        try:
            # å˜—è©¦ç²å–å­—å¹•åˆ—è¡¨
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            available_transcripts = []
            
            for transcript in transcript_list:
                transcript_info = {
                    'language': transcript.language,
                    'language_code': transcript.language_code,
                    'is_generated': transcript.is_generated,
                    'is_translatable': transcript.is_translatable
                }
                available_transcripts.append(transcript_info)
                logger.info(f"ç™¼ç¾å­—å¹•: {transcript_info}")
            
            if available_transcripts:
                logger.info(f"å½±ç‰‡æœ‰ {len(available_transcripts)} å€‹å¯ç”¨å­—å¹•")
                return True, available_transcripts
            else:
                logger.warning("å½±ç‰‡æ²’æœ‰å¯ç”¨å­—å¹•")
                return False, []
                
        except Exception as e:
            logger.error(f"æª¢æŸ¥å­—å¹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False, []
    
    def extract_transcript(self, video_id: str, language_codes: List[str] = None) -> Optional[List[Dict]]:
        """
        æ­¥é©Ÿ 3 & 4: æå–è½‰éŒ„æ–‡å­—
        
        Args:
            video_id: YouTube å½±ç‰‡ ID
            language_codes: åå¥½çš„èªè¨€ä»£ç¢¼åˆ—è¡¨ï¼Œé è¨­ç‚º ['zh-TW', 'zh', 'en']
            
        Returns:
            è½‰éŒ„å…§å®¹åˆ—è¡¨æˆ– None
        """
        if language_codes is None:
            language_codes = ['zh-TW', 'zh-CN', 'zh', 'en']
        
        logger.info(f"æå–å½±ç‰‡è½‰éŒ„: {video_id}")
        
        try:
            # å˜—è©¦ç²å–æŒ‡å®šèªè¨€çš„å­—å¹•
            for lang_code in language_codes:
                try:
                    transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang_code])
                    logger.info(f"æˆåŠŸç²å– {lang_code} å­—å¹•ï¼Œå…± {len(transcript)} å€‹ç‰‡æ®µ")
                    return transcript
                except Exception as e:
                    logger.debug(f"ç„¡æ³•ç²å– {lang_code} å­—å¹•: {e}")
                    continue
            
            # å¦‚æœæŒ‡å®šèªè¨€éƒ½å¤±æ•—ï¼Œå˜—è©¦ç²å–ä»»ä½•å¯ç”¨çš„å­—å¹•
            try:
                transcript = YouTubeTranscriptApi.get_transcript(video_id)
                logger.info(f"ç²å–é è¨­å­—å¹•ï¼Œå…± {len(transcript)} å€‹ç‰‡æ®µ")
                return transcript
            except Exception as e:
                logger.error(f"ç„¡æ³•ç²å–ä»»ä½•å­—å¹•: {e}")
                return None
                
        except Exception as e:
            logger.error(f"æå–è½‰éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def clean_text(self, transcript: List[Dict], remove_timestamps: bool = True) -> str:
        """
        æ­¥é©Ÿ 5: æ¸…ç†è½‰éŒ„æ–‡å­—
        
        Args:
            transcript: è½‰éŒ„å…§å®¹åˆ—è¡¨
            remove_timestamps: æ˜¯å¦ç§»é™¤æ™‚é–“æˆ³
            
        Returns:
            æ¸…ç†å¾Œçš„æ–‡å­—
        """
        logger.info("é–‹å§‹æ¸…ç†è½‰éŒ„æ–‡å­—")
        
        if not transcript:
            return ""
        
        # æå–ç´”æ–‡å­—
        texts = []
        for item in transcript:
            text = item.get('text', '').strip()
            if text:
                # ç§»é™¤å¸¸è¦‹çš„è½‰éŒ„æ¨™è¨˜
                text = re.sub(r'\[.*?\]', '', text)  # ç§»é™¤ [éŸ³æ¨‚]ã€[æŒè²] ç­‰
                text = re.sub(r'\(.*?\)', '', text)  # ç§»é™¤æ‹¬è™Ÿå…§å®¹
                text = re.sub(r'<.*?>', '', text)   # ç§»é™¤ HTML æ¨™ç±¤
                text = re.sub(r'\s+', ' ', text)    # æ¨™æº–åŒ–ç©ºç™½
                text = text.strip()
                
                if text:
                    texts.append(text)
        
        # åˆä½µæ–‡å­—
        full_text = ' '.join(texts)
        
        # é€²ä¸€æ­¥æ¸…ç†
        full_text = re.sub(r'\s+', ' ', full_text)  # å¤šé¤˜ç©ºç™½
        full_text = re.sub(r'([.!?])\s*([A-Z])', r'\1\n\2', full_text)  # å¥å­æ›è¡Œ
        
        logger.info(f"æ–‡å­—æ¸…ç†å®Œæˆï¼Œå…± {len(full_text)} å€‹å­—ç¬¦")
        return full_text.strip()
    
    def identify_speakers(self, transcript: List[Dict]) -> Dict[str, List[str]]:
        """
        æ­¥é©Ÿ 6: è™•ç†å¤šä½è¬›è€…ï¼ˆç°¡å–®å¯¦ç¾ï¼‰
        
        Args:
            transcript: è½‰éŒ„å…§å®¹åˆ—è¡¨
            
        Returns:
            æŒ‰è¬›è€…åˆ†çµ„çš„æ–‡å­—å­—å…¸
        """
        logger.info("å˜—è©¦è­˜åˆ¥å¤šä½è¬›è€…")
        
        speakers = {'æœªçŸ¥è¬›è€…': []}
        
        for item in transcript:
            text = item.get('text', '').strip()
            
            # ç°¡å–®çš„è¬›è€…è­˜åˆ¥æ¨¡å¼
            speaker_patterns = [
                r'^([A-Za-z\u4e00-\u9fff]+)\s*[:ï¼š]\s*(.+)',  # "è¬›è€…å: å…§å®¹"
                r'^\[([^\]]+)\]\s*(.+)',  # "[è¬›è€…å] å…§å®¹"
            ]
            
            speaker_found = False
            for pattern in speaker_patterns:
                match = re.match(pattern, text)
                if match:
                    speaker = match.group(1).strip()
                    content = match.group(2).strip()
                    
                    if speaker not in speakers:
                        speakers[speaker] = []
                    speakers[speaker].append(content)
                    speaker_found = True
                    break
            
            if not speaker_found and text:
                speakers['æœªçŸ¥è¬›è€…'].append(text)
        
        # ç§»é™¤ç©ºçš„è¬›è€…
        speakers = {k: v for k, v in speakers.items() if v}
        
        logger.info(f"è­˜åˆ¥åˆ° {len(speakers)} ä½è¬›è€…")
        return speakers
    
    def correct_transcription_errors(self, text: str) -> str:
        """
        æ­¥é©Ÿ 7: ä¿®æ­£å¸¸è¦‹çš„è½‰éŒ„éŒ¯èª¤
        
        Args:
            text: åŸå§‹æ–‡å­—
            
        Returns:
            ä¿®æ­£å¾Œçš„æ–‡å­—
        """
        logger.info("ä¿®æ­£è½‰éŒ„éŒ¯èª¤")
        
        # å¸¸è¦‹éŒ¯èª¤ä¿®æ­£è¦å‰‡
        corrections = {
            # æ•¸å­—ä¿®æ­£
            r'\bä¸€å€‹\b': '1å€‹',
            r'\bå…©å€‹\b': '2å€‹',
            r'\bä¸‰å€‹\b': '3å€‹',
            
            # æ¨™é»ç¬¦è™Ÿä¿®æ­£
            r'\s+([,ï¼Œ.ã€‚!ï¼?ï¼Ÿ;ï¼›:ï¼š])': r'\1',
            r'([,ï¼Œ.ã€‚!ï¼?ï¼Ÿ;ï¼›:ï¼š])\s*([,ï¼Œ.ã€‚!ï¼?ï¼Ÿ;ï¼›:ï¼š])': r'\1\2',
            
            # ç©ºç™½ä¿®æ­£
            r'\s+': ' ',
        }
        
        corrected_text = text
        for pattern, replacement in corrections.items():
            corrected_text = re.sub(pattern, replacement, corrected_text)
        
        logger.info("è½‰éŒ„éŒ¯èª¤ä¿®æ­£å®Œæˆ")
        return corrected_text.strip()
    
    def save_text(self, text: str, filename: str, format_type: str = 'txt', 
                  video_info: Dict = None, prompt_type: str = None) -> bool:
        """
        æ­¥é©Ÿ 9: å„²å­˜æ–‡å­—
        
        Args:
            text: è¦å„²å­˜çš„æ–‡å­—
            filename: æª”æ¡ˆåç¨±
            format_type: å„²å­˜æ ¼å¼ ('txt', 'json')
            video_info: å½±ç‰‡è³‡è¨Šå­—å…¸
            prompt_type: Prompté¡å‹ï¼Œå¦‚æœæä¾›å‰‡æœƒåœ¨æ–‡ä»¶ä¸­åŒ…å«ç›¸æ‡‰çš„prompt
            
        Returns:
            æ˜¯å¦æˆåŠŸå„²å­˜
        """
        logger.info(f"å„²å­˜æ–‡å­—åˆ° {filename}.{format_type}")
        
        try:
            if format_type.lower() == 'txt':
                content = ""
                
                # å¦‚æœæœ‰å½±ç‰‡è³‡è¨Šï¼Œæ·»åŠ æ¨™é¡Œ
                if video_info:
                    content += f"å½±ç‰‡æ¨™é¡Œï¼š{video_info.get('title', 'æœªçŸ¥å½±ç‰‡')}\n"
                    content += f"å½±ç‰‡ IDï¼š{video_info.get('video_id', '')}\n"
                    content += f"å½±ç‰‡ URLï¼šhttps://www.youtube.com/watch?v={video_info.get('video_id', '')}\n"
                    content += "=" * 60 + "\n\n"
                
                # å¦‚æœæœ‰prompté¡å‹ï¼Œæ·»åŠ ç›¸æ‡‰çš„prompt
                if prompt_type:
                    prompt_templates = self._get_prompt_templates()
                    if prompt_type in prompt_templates:
                        content += f"AI åˆ†æ Prompt ({prompt_type})ï¼š\n"
                        content += "-" * 40 + "\n"
                        content += prompt_templates[prompt_type] + "\n\n"
                        content += "=" * 60 + "\n\n"
                
                # æ·»åŠ æ–‡å­—ç¨¿æ¨™é¡Œ
                content += "YouTube å½±ç‰‡å®Œæ•´æ–‡å­—ç¨¿ï¼š\n"
                content += "-" * 40 + "\n"
                content += text
                
                with open(f"{filename}.txt", 'w', encoding='utf-8') as f:
                    f.write(content)
                    
            elif format_type.lower() == 'json':
                import datetime
                data = {
                    'text': text,
                    'length': len(text),
                    'timestamp': str(datetime.datetime.now()),
                    'video_info': video_info,
                    'prompt_type': prompt_type
                }
                with open(f"{filename}.json", 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
            else:
                logger.error(f"ä¸æ”¯æ´çš„æ ¼å¼: {format_type}")
                return False
            
            logger.info(f"æ–‡å­—æˆåŠŸå„²å­˜åˆ° {filename}.{format_type}")
            return True
            
        except Exception as e:
            logger.error(f"å„²å­˜æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def _get_prompt_templates(self) -> Dict[str, str]:
        """ç²å–ä¸åŒé¡å‹çš„å„ªåŒ– prompt æ¨¡æ¿"""
        return {
            'summary': """ğŸ¯ YouTube å½±ç‰‡æ™ºèƒ½æ‘˜è¦åˆ†æ

è«‹åŸºæ–¼ä»¥ä¸‹å½±ç‰‡å…§å®¹é€²è¡Œå°ˆæ¥­æ‘˜è¦åˆ†æï¼š

ğŸ“‹ **æ‘˜è¦è¦æ±‚ï¼š**
1. **æ ¸å¿ƒå…§å®¹æ‘˜è¦** (3-5å€‹ä¸»è¦è§€é»)
   - æ¯å€‹è§€é»ç”¨1-2å¥è©±ç²¾ç¢ºæ¦‚æ‹¬
   - æ¨™è¨»é‡è¦æ€§ç­‰ç´š (â­â­â­ é«˜é‡è¦æ€§ï¼Œâ­â­ ä¸­ç­‰ï¼Œâ­ ä¸€èˆ¬)

2. **é—œéµæ´å¯Ÿèˆ‡è«–è­‰**
   - å½±ç‰‡æå‡ºçš„ç¨ç‰¹è§€é»æˆ–å‰µæ–°æƒ³æ³•
   - ä¸»è¦è«–è­‰é‚è¼¯å’Œæ”¯æŒè­‰æ“š

3. **å¯¦ç”¨åƒ¹å€¼è©•ä¼°**
   - å°è§€çœ¾çš„å¯¦éš›æ‡‰ç”¨åƒ¹å€¼
   - å¯è¡Œæ€§å’Œæ“ä½œæ€§åˆ†æ

4. **ç›®æ¨™å—çœ¾è­˜åˆ¥**
   - æœ€é©åˆçš„è§€çœ¾ç¾¤é«”
   - å»ºè­°çš„çŸ¥è­˜èƒŒæ™¯è¦æ±‚

5. **å…§å®¹å“è³ªè©•ç´š**
   - è³‡è¨Šæº–ç¢ºåº¦ (A/B/C/D)
   - å…§å®¹æ·±åº¦ (æ·±å…¥/ä¸­ç­‰/åŸºç¤)
   - å¯¦ç”¨æ€§è©•åˆ† (1-10åˆ†)

è«‹ç”¨ç¹é«”ä¸­æ–‡å›è¦†ï¼Œä¸¦ä½¿ç”¨æ¸…æ™°çš„çµæ§‹åŒ–æ ¼å¼ã€‚""",

            'analysis': """ğŸ” YouTube å½±ç‰‡æ·±åº¦å°ˆæ¥­åˆ†æ

è«‹å°ä»¥ä¸‹å½±ç‰‡å…§å®¹é€²è¡Œå…¨é¢çš„å°ˆæ¥­åˆ†æï¼š

ğŸ“Š **åˆ†ææ¶æ§‹ï¼š**

1. **å…§å®¹çµæ§‹è§£æ**
   - å½±ç‰‡é‚è¼¯æ¶æ§‹å’Œçµ„ç¹”æ–¹å¼
   - è³‡è¨Šå±¤æ¬¡å’Œé‡é»åˆ†ä½ˆ
   - æ•˜è¿°æ‰‹æ³•å’Œè¡¨é”æŠ€å·§

2. **è«–è­‰é«”ç³»è©•ä¼°**
   - ä¸»è¦è«–é»è­˜åˆ¥å’Œåˆ†é¡
   - è«–è­‰å¼·åº¦å’ŒèªªæœåŠ›åˆ†æ
   - è­‰æ“šé¡å‹ (æ•¸æ“š/æ¡ˆä¾‹/å°ˆå®¶æ„è¦‹/ç†è«–ä¾æ“š)

3. **é‚è¼¯è„ˆçµ¡æª¢è¦–**
   - æ¨ç†éç¨‹çš„åˆç†æ€§
   - å› æœé—œä¿‚çš„æº–ç¢ºæ€§
   - é‚è¼¯æ¼æ´æˆ–è–„å¼±ç’°ç¯€

4. **å¤šè§’åº¦è§€é»å°æ¯”**
   - å¯èƒ½çš„åé§è§€é»
   - ä¸åŒç«‹å ´çš„è€ƒé‡
   - çˆ­è­°é»å’Œè¨è«–ç©ºé–“

5. **å¯¦ç”¨æ€§èˆ‡å¯è¡Œæ€§**
   - å¯¦éš›æ‡‰ç”¨çš„å¯èƒ½æ€§
   - å¯¦æ–½é›£åº¦å’Œè³‡æºéœ€æ±‚
   - é æœŸæ•ˆæœå’Œé¢¨éšªè©•ä¼°

6. **å»ºè­°æ”¹é€²æ–¹å‘**
   - å…§å®¹å¯ä»¥åŠ å¼·çš„åœ°æ–¹
   - å»ºè­°çš„å¾ŒçºŒæ·±å…¥ç ”ç©¶
   - å¯¦è¸è¡Œå‹•è¨ˆåŠƒ

è«‹ç”¨å°ˆæ¥­ä¸”å®¢è§€çš„è§’åº¦é€²è¡Œåˆ†æï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡å›è¦†ã€‚""",

            'questions': """â“ YouTube å½±ç‰‡å­¸ç¿’å•é¡Œç”Ÿæˆç³»çµ±

åŸºæ–¼ä»¥ä¸‹å½±ç‰‡å…§å®¹ï¼Œè«‹ç”Ÿæˆå¤šå±¤æ¬¡çš„å­¸ç¿’å•é¡Œï¼š

ğŸ“š **å•é¡Œè¨­è¨ˆæ¶æ§‹ï¼š**

1. **åŸºç¤ç†è§£å±¤ (5é¡Œ)**
   - äº‹å¯¦æ€§å•é¡Œï¼šæ¸¬è©¦åŸºæœ¬è³‡è¨ŠæŒæ¡
   - æ¦‚å¿µæ€§å•é¡Œï¼šæª¢é©—é‡è¦æ¦‚å¿µç†è§£
   - æ¨™è¨»ç­”æ¡ˆå¯åœ¨å½±ç‰‡ä¸­çš„å¤§æ¦‚æ™‚é–“ä½ç½®

2. **åˆ†ææ€è€ƒå±¤ (3é¡Œ)**
   - æ¯”è¼ƒåˆ†æï¼šä¸åŒè§€é»æˆ–æ–¹æ³•çš„å°æ¯”
   - å› æœæ¨ç†ï¼šåŸå› çµæœé—œä¿‚çš„æ¢è¨
   - æ‰¹åˆ¤æ€è€ƒï¼šå„ªç¼ºé»å’Œé™åˆ¶æ€§åˆ†æ

3. **æ‡‰ç”¨å¯¦è¸å±¤ (2é¡Œ)**
   - æƒ…å¢ƒæ‡‰ç”¨ï¼šå¦‚ä½•åœ¨å¯¦éš›æƒ…æ³ä¸­é‹ç”¨
   - å•é¡Œè§£æ±ºï¼šé¢å°ç›¸é—œæŒ‘æˆ°æ™‚çš„ç­–ç•¥

4. **å‰µæ–°å»¶ä¼¸å±¤ (2é¡Œ)**
   - å‡è¨­æ¨è«–ï¼šåŸºæ–¼å…§å®¹çš„é€²ä¸€æ­¥æ¨æ¸¬
   - è·¨é ˜åŸŸé€£çµï¼šèˆ‡å…¶ä»–çŸ¥è­˜çš„é—œè¯

5. **å­¸ç¿’è·¯å¾‘å»ºè­°**
   - æ¨è–¦çš„å»¶ä¼¸é–±è®€æˆ–å­¸ç¿’è³‡æº
   - ç›¸é—œæŠ€èƒ½çš„ç™¼å±•å»ºè­°
   - å¯¦è¸ç·´ç¿’çš„å…·é«”æ–¹å‘

æ¯å€‹å•é¡Œè«‹æ¨™è¨»ï¼š
- ğŸ¯ é›£åº¦ç­‰ç´š (åˆç´š/ä¸­ç´š/é«˜ç´š)
- â° å»ºè­°æ€è€ƒæ™‚é–“
- ğŸ’¡ æ€è€ƒæç¤ºæˆ–é—œéµå­—

è«‹ç”¨ç¹é«”ä¸­æ–‡è¨­è¨ˆå•é¡Œã€‚""",

            'translation': """ğŸŒ YouTube å½±ç‰‡å¤šèªè¨€å„ªåŒ–ç¿»è­¯

è«‹å°ä»¥ä¸‹å½±ç‰‡æ–‡å­—ç¨¿é€²è¡Œå°ˆæ¥­çš„èªè¨€å„ªåŒ–å’Œç¿»è­¯ï¼š

ğŸ“ **ç¿»è­¯å„ªåŒ–æµç¨‹ï¼š**

1. **åŸæ–‡èªè¨€è­˜åˆ¥èˆ‡æ¸…ç†**
   - è­˜åˆ¥ä¸»è¦èªè¨€å’Œæ–¹è¨€ç‰¹è‰²
   - æ¸…ç†èªéŸ³è½‰æ–‡å­—çš„å¸¸è¦‹éŒ¯èª¤
   - æ¨™æº–åŒ–æ¨™é»ç¬¦è™Ÿå’Œæ ¼å¼

2. **ç¹é«”ä¸­æ–‡å„ªåŒ–ç‰ˆæœ¬**
   - æå‡èªè¨€æµæš¢åº¦å’Œå¯è®€æ€§
   - çµ±ä¸€å°ˆæ¥­è¡“èªç¿»è­¯
   - èª¿æ•´èªå¥çµæ§‹ï¼Œç¬¦åˆç¹é«”ä¸­æ–‡è¡¨é”ç¿’æ…£
   - æ·»åŠ é©ç•¶çš„èªæ°£è©å’Œé€£æ¥è©

3. **è‹±æ–‡å°ˆæ¥­ç¿»è­¯**
   - æº–ç¢ºå‚³é”åŸæ„å’Œèªèª¿
   - ä½¿ç”¨æ°ç•¶çš„è‹±æ–‡è¡¨é”æ–¹å¼
   - ä¿æŒå°ˆæ¥­è¡“èªçš„ä¸€è‡´æ€§
   - è€ƒæ…®ç›®æ¨™è®€è€…çš„æ–‡åŒ–èƒŒæ™¯

4. **é—œéµè¡“èªå°ç…§è¡¨**
   - åˆ—å‡ºé‡è¦å°ˆæ¥­è©å½™çš„ä¸­è‹±å°ç…§
   - æä¾›è¡“èªçš„ç°¡è¦è§£é‡‹
   - æ¨™è¨»è¡Œæ¥­æ¨™æº–ç”¨æ³•

5. **å…§å®¹çµæ§‹é‡çµ„**
   - æŒ‰é‚è¼¯ä¸»é¡Œé‡æ–°çµ„ç¹”å…§å®¹
   - æå–é‡é»æ‘˜è¦
   - è£½ä½œç°¡æ½”çš„è¦é»åˆ—è¡¨

6. **æ–‡åŒ–é©æ‡‰æ€§èª¿æ•´**
   - è§£é‡‹æ–‡åŒ–ç‰¹å®šçš„æ¦‚å¿µæˆ–ä¾‹å­
   - æä¾›åœ¨åœ°åŒ–çš„é¡æ¯”æˆ–æ¡ˆä¾‹
   - æ¨™è¨»å¯èƒ½éœ€è¦é¡å¤–èƒŒæ™¯çŸ¥è­˜çš„éƒ¨åˆ†

è«‹ç¢ºä¿ç¿»è­¯çš„æº–ç¢ºæ€§ã€å°ˆæ¥­æ€§å’Œå¯è®€æ€§ã€‚""",

            'mindmap': """ğŸ§  YouTube å½±ç‰‡å¿ƒæ™ºåœ–çµæ§‹è¨­è¨ˆ

è«‹ç‚ºä»¥ä¸‹å½±ç‰‡å…§å®¹å‰µå»ºå®Œæ•´çš„å¿ƒæ™ºåœ–çµæ§‹ï¼š

ğŸ—ºï¸ **å¿ƒæ™ºåœ–è¨­è¨ˆåŸå‰‡ï¼š**

1. **ä¸­å¿ƒä¸»é¡Œç¢ºç«‹**
   - å½±ç‰‡çš„æ ¸å¿ƒæ¦‚å¿µ (æ”¾ç½®æ–¼ä¸­å¿ƒ)
   - ä¸»é¡Œçš„ç°¡æ½”æè¿° (1-2å€‹é—œéµè©)

2. **ä¸»è¦åˆ†æ”¯æ¶æ§‹ (3-7å€‹ä¸»åˆ†æ”¯)**
   - ç¬¬ä¸€å±¤ï¼šä¸»è¦æ¦‚å¿µæˆ–ç« ç¯€
   - ä½¿ç”¨ä¸åŒé¡è‰²æ¨™è¨˜å„åˆ†æ”¯
   - æ¯å€‹åˆ†æ”¯ç”¨å‹•è©æˆ–åè©çŸ­èªè¡¨é”

3. **æ¬¡ç´šç¯€é»å±•é–‹ (æ¯å€‹ä¸»åˆ†æ”¯2-5å€‹å­ç¯€é»)**
   - ç¬¬äºŒå±¤ï¼šå…·é«”è¦é»æˆ–å­æ¦‚å¿µ
   - åŒ…å«é‡è¦çš„ç´°ç¯€æˆ–ä¾‹å­
   - ä½¿ç”¨é—œéµè©è€Œéå®Œæ•´å¥å­

4. **é—œè¯ç·šæ¢è¨­è¨ˆ**
   - æ¨™ç¤ºåˆ†æ”¯é–“çš„ç›¸äº’é—œä¿‚
   - ç”¨è™›ç·šè¡¨ç¤ºé–“æ¥é—œè¯
   - ç”¨ç®­é ­è¡¨ç¤ºå› æœé—œä¿‚æˆ–æµç¨‹

5. **è¦–è¦ºå…ƒç´ å»ºè­°**
   - ğŸ¨ é¡è‰²ç·¨ç¢¼æ–¹æ¡ˆ
   - ğŸ“Š åœ–ç¤ºå’Œç¬¦è™Ÿå»ºè­°
   - ğŸ“ ç›¸å°é‡è¦æ€§çš„å¤§å°å€åˆ†

6. **è¨˜æ†¶è¼”åŠ©æŠ€å·§**
   - åŠ©è¨˜å£è¨£æˆ–é—œéµå­—è¯æƒ³
   - é‚è¼¯è¨˜æ†¶é †åºå»ºè­°
   - è¤‡ç¿’è¦é»æé†’

7. **å­¸ç¿’è·¯å¾‘æŒ‡å¼•**
   - å»ºè­°çš„å­¸ç¿’é †åº (1â†’2â†’3...)
   - é‡é»è¤‡ç¿’ç¯€é»æ¨™è¨˜ â­
   - å»¶ä¼¸å­¸ç¿’æ–¹å‘å»ºè­°

è«‹ç”¨å±¤æ¬¡åˆ†æ˜çš„çµæ§‹åŒ–æ ¼å¼å‘ˆç¾ï¼Œä¾¿æ–¼è£½ä½œå¯¦éš›çš„å¿ƒæ™ºåœ–ã€‚""",

            'historical_verification': """ğŸ“Š YouTube å½±ç‰‡æ­·å²æ•¸æ“šé©—è­‰åˆ†æ

è«‹åŸºæ–¼å½±ç‰‡å…§å®¹é€²è¡Œæ­·å²æ•¸æ“šé©—è­‰å’Œäº‹å¯¦æ ¸æŸ¥ï¼š

ğŸ” **é©—è­‰åˆ†ææ¶æ§‹ï¼š**

1. **äº‹å¯¦æ ¸æŸ¥å±¤é¢**
   - è­˜åˆ¥å½±ç‰‡ä¸­çš„å…·é«”æ•¸æ“šã€çµ±è¨ˆè³‡æ–™å’Œäº‹å¯¦è²æ˜
   - æ¨™è¨»éœ€è¦é©—è­‰çš„é—œéµä¿¡æ¯
   - è©•ä¼°è³‡è¨Šçš„å¯ä¿¡åº¦ç­‰ç´š (é«˜/ä¸­/ä½)

2. **æ­·å²è¶¨å‹¢å°æ¯”**
   - å°‡å½±ç‰‡è«–é»èˆ‡æ­·å²æ•¸æ“šé€²è¡Œå°æ¯”
   - è­˜åˆ¥èˆ‡éå¾€è¶¨å‹¢çš„ä¸€è‡´æ€§æˆ–å·®ç•°
   - åˆ†ææ•¸æ“šçš„æ™‚æ•ˆæ€§å’Œç›¸é—œæ€§

3. **è³‡æ–™ä¾†æºè©•ä¼°**
   - è©•ä¼°å½±ç‰‡å¼•ç”¨çš„è³‡æ–™ä¾†æºå“è³ª
   - è­˜åˆ¥å¯èƒ½çš„åè¦‹æˆ–å±€é™æ€§
   - å»ºè­°æ›´æ¬Šå¨æˆ–æœ€æ–°çš„è³‡æ–™ä¾†æº

4. **æ•¸æ“šå¯é æ€§åˆ†æ**
   - æª¢è¦–çµ±è¨ˆæ–¹æ³•çš„åˆç†æ€§
   - è­˜åˆ¥å¯èƒ½çš„æ¨£æœ¬åå·®æˆ–éŒ¯èª¤
   - è©•ä¼°æ•¸æ“šè§£è®€çš„æº–ç¢ºæ€§

5. **æ™‚é–“è„ˆçµ¡æª¢é©—**
   - åˆ†æè«–é»åœ¨ä¸åŒæ™‚æœŸçš„é©ç”¨æ€§
   - è­˜åˆ¥å¯èƒ½å·²éæ™‚çš„è³‡è¨Š
   - è©•ä¼°æŒçºŒæœ‰æ•ˆæ€§

6. **äº¤å‰é©—è­‰å»ºè­°**
   - å»ºè­°æŸ¥è­‰çš„æ¬Šå¨è³‡æ–™åº«æˆ–æ©Ÿæ§‹
   - æä¾›ç›¸é—œçš„ç ”ç©¶å ±å‘Šæˆ–å­¸è¡“æ–‡ç»
   - åˆ—å‡ºå¯ä»¥é€²ä¸€æ­¥æ ¸å¯¦çš„å®˜æ–¹è³‡æº

7. **çµè«–å¯ä¿¡åº¦è©•ç´š**
   - æ•´é«”äº‹å¯¦æº–ç¢ºåº¦è©•åˆ† (A/B/C/D)
   - æ¨™è¨»é«˜å¯ä¿¡åº¦çš„éƒ¨åˆ† âœ…
   - æ¨™è¨»éœ€è¦è¬¹æ…å°å¾…çš„éƒ¨åˆ† âš ï¸
   - æ¨™è¨»å¯èƒ½æœ‰èª¤çš„éƒ¨åˆ† âŒ

è«‹ä»¥å®¢è§€ã€å°ˆæ¥­çš„æ…‹åº¦é€²è¡Œé©—è­‰åˆ†æã€‚""",

            'trend_analysis': """ğŸ“ˆ YouTube å½±ç‰‡è¶¨å‹¢åˆ†æèˆ‡é æ¸¬

è«‹å°å½±ç‰‡å…§å®¹é€²è¡Œè¶¨å‹¢è­˜åˆ¥å’Œç™¼å±•æ–¹å‘åˆ†æï¼š

ğŸ”® **è¶¨å‹¢åˆ†ææ¡†æ¶ï¼š**

1. **ç•¶å‰è¶¨å‹¢è­˜åˆ¥**
   - å½±ç‰‡åæ˜ çš„ç¾æœ‰è¶¨å‹¢å’Œæ¨¡å¼
   - è¶¨å‹¢çš„ç™¼å±•éšæ®µ (èŒèŠ½æœŸ/æˆé•·æœŸ/æˆç†ŸæœŸ/è¡°é€€æœŸ)
   - è¶¨å‹¢çš„å½±éŸ¿ç¯„åœå’Œæ·±åº¦

2. **æ­·å²ç™¼å±•è»Œè·¡**
   - è¿½æº¯ç›¸é—œé ˜åŸŸçš„æ­·å²ç™¼å±•
   - è­˜åˆ¥é‡è¦çš„è½‰æŠ˜é»å’Œé‡Œç¨‹ç¢‘
   - åˆ†æé€±æœŸæ€§æ¨¡å¼æˆ–è¦å¾‹

3. **é©…å‹•å› ç´ åˆ†æ**
   - æŠ€è¡“é€²æ­¥çš„æ¨å‹•ä½œç”¨
   - ç¤¾æœƒéœ€æ±‚çš„è®ŠåŒ–
   - æ”¿ç­–ç’°å¢ƒçš„å½±éŸ¿
   - ç¶“æ¿Ÿå› ç´ çš„ä½œç”¨

4. **æœªä¾†ç™¼å±•é æ¸¬**
   - çŸ­æœŸç™¼å±•é æ¸¬ (1-2å¹´)
   - ä¸­æœŸè¶¨å‹¢å±•æœ› (3-5å¹´)
   - é•·æœŸå‰æ™¯åˆ†æ (5-10å¹´)

5. **æ©Ÿæœƒèˆ‡é¢¨éšªè©•ä¼°**
   - æ½›åœ¨çš„ç™¼å±•æ©Ÿæœƒ
   - å¯èƒ½é¢è‡¨çš„æŒ‘æˆ°å’Œé¢¨éšª
   - ä¸ç¢ºå®šæ€§å› ç´ åˆ†æ

6. **å½±éŸ¿å› å­ç›£æ¸¬**
   - éœ€è¦æŒçºŒé—œæ³¨çš„é—œéµæŒ‡æ¨™
   - å¯èƒ½æ”¹è®Šè¶¨å‹¢çš„é‡è¦å› ç´ 
   - é è­¦ä¿¡è™Ÿå’Œè½‰æŠ˜é»

7. **ç­–ç•¥å»ºè­°**
   - å€‹äººæˆ–çµ„ç¹”çš„æ‡‰å°ç­–ç•¥
   - æŠ•è³‡æˆ–ç™¼å±•å»ºè­°
   - é¢¨éšªè¦é¿æªæ–½

è«‹åŸºæ–¼æ•¸æ“šå’Œé‚è¼¯é€²è¡Œåˆ†æï¼Œæä¾›å…·é«”ä¸”å¯è¡Œçš„æ´å¯Ÿã€‚""",

            'future_prediction': """ğŸš€ YouTube å½±ç‰‡æœªä¾†é æ¸¬åˆ†æ

åŸºæ–¼å½±ç‰‡å…§å®¹ï¼Œè«‹é€²è¡Œç³»çµ±æ€§çš„æœªä¾†é æ¸¬åˆ†æï¼š

ğŸ”­ **é æ¸¬åˆ†æé«”ç³»ï¼š**

1. **åŸºæº–ç¾ç‹€è©•ä¼°**
   - ç•¶å‰ç‹€æ³çš„å…¨é¢æè¿°
   - é—œéµæŒ‡æ¨™çš„åŸºæº–å€¼
   - å½±éŸ¿å› ç´ çš„æ¬Šé‡åˆ†æ

2. **æƒ…å¢ƒå»ºæ¨¡é æ¸¬**
   - **æ¨‚è§€æƒ…å¢ƒ** ğŸŒŸ
     * æœ€ç†æƒ³ç™¼å±•æ¢ä»¶ä¸‹çš„å¯èƒ½çµæœ
     * å¯¦ç¾æ©Ÿç‡è©•ä¼° (%)
     * é—œéµæˆåŠŸå› ç´ 

   - **åŸºæº–æƒ…å¢ƒ** ğŸ“Š
     * åŸºæ–¼ç¾æœ‰è¶¨å‹¢çš„åˆç†é æœŸ
     * æœ€å¯èƒ½çš„ç™¼å±•è·¯å¾‘
     * é æœŸæ™‚é–“æ¡†æ¶

   - **æ‚²è§€æƒ…å¢ƒ** âš ï¸
     * é¢è‡¨é‡å¤§æŒ‘æˆ°æ™‚çš„å¯èƒ½å¾Œæœ
     * é¢¨éšªå› ç´ å’Œé˜»ç¤™
     * æ‡‰å°å’Œç·©è§£ç­–ç•¥

3. **æ™‚é–“ç·šé æ¸¬**
   - **è¿‘æœŸ (6å€‹æœˆ-1å¹´)**
     * ç¢ºå®šæ€§è¼ƒé«˜çš„è®ŠåŒ–
     * å¯è§€å¯Ÿçš„æ—©æœŸæŒ‡æ¨™

   - **ä¸­æœŸ (1-3å¹´)**
     * ä¸­ç­‰ç¢ºå®šæ€§çš„ç™¼å±•
     * éœ€è¦ç›£æ¸¬çš„é—œéµç¯€é»

   - **é æœŸ (3-10å¹´)**
     * å¯èƒ½æ€§ç¯„åœè¼ƒå»£çš„è®ŠåŒ–
     * é¡›è¦†æ€§å› ç´ çš„æ½›åœ¨å½±éŸ¿

4. **å½±éŸ¿è©•ä¼°çŸ©é™£**
   - å°ä¸åŒåˆ©å®³é—œä¿‚äººçš„å½±éŸ¿ç¨‹åº¦
   - ç¤¾æœƒã€ç¶“æ¿Ÿã€æŠ€è¡“å±¤é¢çš„è¡æ“Š
   - æ­£é¢å’Œè² é¢æ•ˆæ‡‰çš„å¹³è¡¡

5. **ä¸ç¢ºå®šæ€§åˆ†æ**
   - é æ¸¬çš„å¯ä¿¡åº¦å€é–“
   - ä¸»è¦çš„ä¸ç¢ºå®šæ€§ä¾†æº
   - å¯èƒ½æ”¹è®Šé æ¸¬çš„é—œéµå› ç´ 

6. **ç›£æ¸¬æŒ‡æ¨™è¨­è¨ˆ**
   - è¿½è¹¤é æ¸¬æº–ç¢ºæ€§çš„é—œéµæŒ‡æ¨™
   - æ—©æœŸé è­¦ä¿¡è™Ÿ
   - ä¿®æ­£é æ¸¬çš„è§¸ç™¼æ¢ä»¶

7. **è¡Œå‹•å»ºè­°**
   - åŸºæ–¼é æ¸¬çš„æˆ°ç•¥è¦åŠƒå»ºè­°
   - é¢¨éšªç®¡ç†å’Œæ©ŸæœƒæŠŠæ¡ç­–ç•¥
   - é©æ‡‰æ€§èª¿æ•´çš„æº–å‚™æ–¹æ¡ˆ

8. **é æ¸¬æ›´æ–°æ©Ÿåˆ¶**
   - å®šæœŸé‡æ–°è©•ä¼°çš„æ™‚é–“é»
   - æ–°è³‡è¨Šæ•´åˆçš„æ–¹æ³•
   - é æ¸¬æ¨¡å‹çš„æŒçºŒå„ªåŒ–

âš ï¸ **é‡è¦è²æ˜ï¼š**
æ­¤é æ¸¬åŸºæ–¼ç•¶å‰å¯å¾—è³‡è¨Šï¼Œå¯¦éš›ç™¼å±•å¯èƒ½å—åˆ°ä¸å¯é è¦‹å› ç´ å½±éŸ¿ã€‚
å»ºè­°å°‡æ­¤ä½œç‚ºåƒè€ƒå·¥å…·ï¼Œä¸¦çµåˆæœ€æ–°è³‡è¨ŠæŒçºŒæ›´æ–°åˆ¤æ–·ã€‚

è«‹æä¾›é‚è¼¯æ¸…æ™°ã€è­‰æ“šå……åˆ†çš„é æ¸¬åˆ†æã€‚""",

            'industry_insight': """ğŸ¢ YouTube å½±ç‰‡è¡Œæ¥­æ´å¯Ÿåˆ†æ

è«‹å¾è¡Œæ¥­å°ˆæ¥­è§’åº¦æ·±åº¦è§£æå½±ç‰‡å…§å®¹ï¼š

ğŸ’¼ **è¡Œæ¥­åˆ†æç¶­åº¦ï¼š**

1. **è¡Œæ¥­å®šä½åˆ†æ**
   - å½±ç‰‡æ¶‰åŠçš„ä¸»è¦è¡Œæ¥­é ˜åŸŸ
   - åœ¨ç”¢æ¥­éˆä¸­çš„ä½ç½®å’Œè§’è‰²
   - èˆ‡å…¶ä»–è¡Œæ¥­çš„é—œè¯æ€§

2. **å¸‚å ´ç’°å¢ƒè©•ä¼°**
   - ç›®æ¨™å¸‚å ´çš„è¦æ¨¡å’Œç‰¹å¾µ
   - ç«¶çˆ­æ ¼å±€å’Œä¸»è¦åƒèˆ‡è€…
   - å¸‚å ´æˆç†Ÿåº¦å’Œç™¼å±•æ½›åŠ›

3. **å•†æ¥­æ¨¡å¼è§£æ**
   - åƒ¹å€¼å‰µé€ å’Œå‚³éæ©Ÿåˆ¶
   - æ”¶ç›Šæ¨¡å¼å’Œç›ˆåˆ©é»
   - æˆæœ¬çµæ§‹å’Œæ•ˆç‡åˆ†æ

4. **æŠ€è¡“å‰µæ–°å½±éŸ¿**
   - ç›¸é—œæŠ€è¡“çš„ç™¼å±•æ°´å¹³
   - æŠ€è¡“å‰µæ–°å°è¡Œæ¥­çš„æ”¹è®Š
   - æœªä¾†æŠ€è¡“è¶¨å‹¢çš„æ½›åœ¨è¡æ“Š

5. **æ”¿ç­–æ³•è¦ç’°å¢ƒ**
   - ç›¸é—œæ”¿ç­–çš„æ”¯æŒæˆ–é™åˆ¶
   - æ³•è¦è®ŠåŒ–çš„å½±éŸ¿è©•ä¼°
   - åˆè¦è¦æ±‚å’ŒæŒ‘æˆ°

6. **æŠ•è³‡èˆ‡è²¡å‹™åˆ†æ**
   - è¡Œæ¥­æŠ•è³‡ç†±é»å’Œè³‡é‡‘æµå‘
   - ä¼°å€¼æ°´å¹³å’ŒæŠ•è³‡å›å ±
   - è²¡å‹™é¢¨éšªå’Œæ©Ÿæœƒ

7. **äººæ‰èˆ‡è³‡æºéœ€æ±‚**
   - é—œéµäººæ‰çš„éœ€æ±‚å’Œä¾›çµ¦
   - æ ¸å¿ƒè³‡æºçš„ç¨€ç¼ºæ€§
   - èƒ½åŠ›å»ºè¨­çš„é‡é»æ–¹å‘

8. **ç­–ç•¥å»ºè­°**
   - é€²å…¥ç­–ç•¥å’Œæ™‚æ©Ÿé¸æ“‡
   - ç«¶çˆ­å„ªå‹¢çš„å»ºç«‹æ–¹å¼
   - é¢¨éšªç®¡æ§å’Œæ©ŸæœƒæŠŠæ¡

è«‹å¾å°ˆæ¥­æŠ•è³‡è€…æˆ–è¡Œæ¥­å°ˆå®¶çš„è§’åº¦æä¾›æ·±åº¦æ´å¯Ÿã€‚""",

            'fact_check': """âœ… YouTube å½±ç‰‡äº‹å¯¦æ ¸æŸ¥å ±å‘Š

è«‹å°å½±ç‰‡ä¸­çš„é—œéµè²æ˜é€²è¡Œç³»çµ±æ€§äº‹å¯¦æ ¸æŸ¥ï¼š

ğŸ” **äº‹å¯¦æ ¸æŸ¥æµç¨‹ï¼š**

1. **è²æ˜è­˜åˆ¥èˆ‡åˆ†é¡**
   - æå–å½±ç‰‡ä¸­çš„å…·é«”äº‹å¯¦è²æ˜
   - åˆ†é¡ï¼šæ•¸æ“š/çµ±è¨ˆ/æ­·å²äº‹ä»¶/ç§‘å­¸è«–è¿°/å¼•ç”¨
   - æ¨™è¨»è²æ˜çš„é‡è¦æ€§ç´šåˆ¥

2. **æ ¸æŸ¥çµæœè©•ç´š**
   - âœ… **å®Œå…¨æ­£ç¢º**ï¼šç¶“æ¬Šå¨ä¾†æºè­‰å¯¦
   - âš ï¸ **éƒ¨åˆ†æ­£ç¢º**ï¼šåŸºæœ¬æ­£ç¢ºä½†æœ‰ç´°ç¯€åå·®
   - â“ **éœ€è¦æŸ¥è­‰**ï¼šç„¡æ³•ç¢ºèªæˆ–ä¾†æºä¸æ˜
   - âŒ **æ˜ç¢ºéŒ¯èª¤**ï¼šèˆ‡æ¬Šå¨è³‡æ–™ä¸ç¬¦
   - ğŸ”„ **éæ™‚è³‡è¨Š**ï¼šæ›¾ç¶“æ­£ç¢ºä½†å·²éæœŸ

3. **è­‰æ“šä¾†æºè©•ä¼°**
   - ä¸€æ‰‹è³‡æ–™ï¼šå®˜æ–¹çµ±è¨ˆã€ç ”ç©¶å ±å‘Šã€æ”¿åºœæ•¸æ“š
   - äºŒæ‰‹è³‡æ–™ï¼šæ–°èå ±å°ã€å°ˆæ¥­åª’é«”ã€å­¸è¡“æ–‡ç»
   - æ¬Šå¨æ©Ÿæ§‹ï¼šWHOã€è¯åˆåœ‹ã€å¤®è¡Œã€çŸ¥åç ”ç©¶æ©Ÿæ§‹
   - ä¾†æºå¯ä¿¡åº¦è©•åˆ† (A+/A/B/C/D)

4. **æ•¸æ“šæº–ç¢ºæ€§æª¢é©—**
   - æ•¸å­—çš„ç²¾ç¢ºæ€§å’Œæ™‚æ•ˆæ€§
   - çµ±è¨ˆæ–¹æ³•çš„åˆç†æ€§
   - æ¨£æœ¬ä»£è¡¨æ€§å’Œåå·®åˆ†æ
   - è³‡æ–™è§£è®€çš„å®¢è§€æ€§

5. **è„ˆçµ¡å®Œæ•´æ€§è©•ä¼°**
   - æ˜¯å¦å­˜åœ¨æ–·ç« å–ç¾©
   - é‡è¦è„ˆçµ¡è³‡è¨Šçš„éºæ¼
   - åè¦‹æˆ–å‚¾å‘æ€§è¡¨é”

6. **æ›´æ­£å»ºè­°**
   - éŒ¯èª¤è³‡è¨Šçš„æ­£ç¢ºç‰ˆæœ¬
   - è£œå……ç¼ºå¤±çš„é‡è¦è³‡è¨Š
   - æ›´æ¬Šå¨çš„è³‡æ–™ä¾†æº

7. **ç¸½é«”å¯ä¿¡åº¦è©•ä¼°**
   - æ•´é«”äº‹å¯¦æº–ç¢ºåº¦ (1-10åˆ†)
   - ä¸»è¦å¯ä¿¡éƒ¨åˆ†ç¸½çµ
   - éœ€è¦è³ªç–‘çš„éƒ¨åˆ†æé†’

è«‹ä¿æŒå®¢è§€ä¸­ç«‹ï¼ŒåŸºæ–¼äº‹å¯¦é€²è¡Œæ ¸æŸ¥ã€‚"""
        }
    
    def create_ai_ready_file(self, video_url: str, prompt_type: str = 'summary', 
                           output_dir: str = "ai_uploads") -> Optional[str]:
        """
        å‰µå»ºæº–å‚™ä¸Šå‚³åˆ° AI çš„æ–‡ä»¶
        
        Args:
            video_url: YouTube å½±ç‰‡ URL
            prompt_type: Prompt é¡å‹
            output_dir: è¼¸å‡ºç›®éŒ„
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾‘æˆ– None
        """
        logger.info(f"å‰µå»º AI æº–å‚™æ–‡ä»¶: {video_url}, prompt_type: {prompt_type}")
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # è™•ç†å½±ç‰‡
        result = self.process_video(video_url)
        
        if not result['success']:
            logger.error(f"å½±ç‰‡è™•ç†å¤±æ•—: {result.get('error')}")
            return None
        
        # æº–å‚™å½±ç‰‡è³‡è¨Š
        video_info = {
            'video_id': result['video_id'],
            'title': f"YouTube Video {result['video_id']}",
            'url': f"https://www.youtube.com/watch?v={result['video_id']}"
        }
        
        # å¦‚æœæœ‰ YouTube APIï¼Œç²å–æ›´è©³ç´°çš„å½±ç‰‡è³‡è¨Š
        if self.youtube_service:
            try:
                video_response = self.youtube_service.videos().list(
                    part='snippet,statistics',
                    id=result['video_id']
                ).execute()
                
                if video_response['items']:
                    snippet = video_response['items'][0]['snippet']
                    statistics = video_response['items'][0]['statistics']
                    
                    video_info.update({
                        'title': snippet.get('title', video_info['title']),
                        'description': snippet.get('description', ''),
                        'channel_title': snippet.get('channelTitle', ''),
                        'published_at': snippet.get('publishedAt', ''),
                        'view_count': statistics.get('viewCount', ''),
                        'like_count': statistics.get('likeCount', ''),
                        'comment_count': statistics.get('commentCount', '')
                    })
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç²å–å½±ç‰‡è©³ç´°è³‡è¨Š: {e}")
        
        # ç”Ÿæˆæ–‡ä»¶å
        safe_title = re.sub(r'[^\w\s-]', '', video_info['title'][:50])
        safe_title = re.sub(r'[-\s]+', '-', safe_title)
        filename = f"{output_dir}/{result['video_id']}_{prompt_type}_{safe_title}"
        
        # å„²å­˜æ–‡ä»¶
        if self.save_text(result['text'], filename, 'txt', video_info, prompt_type):
            file_path = f"{filename}.txt"
            logger.info(f"AI æº–å‚™æ–‡ä»¶å·²å‰µå»º: {file_path}")
            return file_path
        
        return None
    
    def get_available_prompt_types(self) -> Dict[str, Dict[str, str]]:
        """
        ç²å–æ‰€æœ‰å¯ç”¨çš„ Prompt é¡å‹åŠå…¶è©³ç´°èªªæ˜
        
        Returns:
            åŒ…å« prompt é¡å‹è³‡è¨Šçš„å­—å…¸
        """
        return {
            'summary': {
                'name': 'ğŸ“ æ™ºèƒ½æ‘˜è¦åˆ†æ',
                'description': 'å°ˆæ¥­æ‘˜è¦åˆ†æï¼ŒåŒ…å«æ ¸å¿ƒè§€é»ã€å¯¦ç”¨åƒ¹å€¼è©•ä¼°å’Œå…§å®¹å“è³ªè©•ç´š',
                'suitable_for': 'å¿«é€Ÿäº†è§£å½±ç‰‡é‡é»ã€å­¸ç¿’ç­†è¨˜æ•´ç†ã€å…§å®¹è©•ä¼°',
                'output_focus': 'çµæ§‹åŒ–æ‘˜è¦ã€é‡è¦æ€§åˆ†ç´šã€å¯¦ç”¨å»ºè­°'
            },
            'analysis': {
                'name': 'ğŸ” æ·±åº¦å°ˆæ¥­åˆ†æ', 
                'description': 'å…¨é¢çš„å°ˆæ¥­åˆ†æï¼ŒåŒ…å«è«–è­‰é«”ç³»ã€é‚è¼¯æª¢è¦–å’Œå¤šè§’åº¦å°æ¯”',
                'suitable_for': 'å­¸è¡“ç ”ç©¶ã€æ‰¹åˆ¤æ€§æ€è€ƒã€å°ˆæ¥­è©•ä¼°',
                'output_focus': 'é‚è¼¯æ¶æ§‹ã€è«–è­‰å¼·åº¦ã€æ”¹é€²å»ºè­°'
            },
            'questions': {
                'name': 'â“ å­¸ç¿’å•é¡Œç”Ÿæˆ',
                'description': 'å¤šå±¤æ¬¡å­¸ç¿’å•é¡Œè¨­è¨ˆï¼Œå¾åŸºç¤ç†è§£åˆ°å‰µæ–°å»¶ä¼¸',
                'suitable_for': 'æ•™å­¸è¨­è¨ˆã€è‡ªä¸»å­¸ç¿’ã€çŸ¥è­˜æª¢æ¸¬',
                'output_focus': 'åˆ†å±¤å•é¡Œã€å­¸ç¿’è·¯å¾‘ã€æ€è€ƒæç¤º'
            },
            'translation': {
                'name': 'ğŸŒ å¤šèªè¨€å„ªåŒ–ç¿»è­¯',
                'description': 'å°ˆæ¥­èªè¨€å„ªåŒ–å’Œç¿»è­¯ï¼ŒåŒ…å«è¡“èªå°ç…§å’Œæ–‡åŒ–é©æ‡‰',
                'suitable_for': 'è·¨èªè¨€å­¸ç¿’ã€å…§å®¹æœ¬åœ°åŒ–ã€å°ˆæ¥­ç¿»è­¯',
                'output_focus': 'èªè¨€å„ªåŒ–ã€è¡“èªå°ç…§ã€æ–‡åŒ–èª¿æ•´'
            },
            'mindmap': {
                'name': 'ğŸ§  å¿ƒæ™ºåœ–çµæ§‹è¨­è¨ˆ',
                'description': 'å®Œæ•´å¿ƒæ™ºåœ–çµæ§‹å‰µå»ºï¼ŒåŒ…å«è¦–è¦ºå…ƒç´ å’Œè¨˜æ†¶æŠ€å·§',
                'suitable_for': 'çŸ¥è­˜æ•´ç†ã€è¨˜æ†¶å¼·åŒ–ã€æ¦‚å¿µé—œè¯',
                'output_focus': 'çµæ§‹åŒ–å¸ƒå±€ã€è¦–è¦ºè¨­è¨ˆã€å­¸ç¿’è·¯å¾‘'
            },
            'historical_verification': {
                'name': 'ğŸ“Š æ­·å²æ•¸æ“šé©—è­‰',
                'description': 'åŸºæ–¼æ­·å²æ•¸æ“šçš„äº‹å¯¦æ ¸æŸ¥å’Œå¯ä¿¡åº¦è©•ä¼°',
                'suitable_for': 'äº‹å¯¦æ ¸æŸ¥ã€è³‡æ–™é©—è­‰ã€å¯ä¿¡åº¦è©•ä¼°',
                'output_focus': 'æ•¸æ“šå°æ¯”ã€ä¾†æºè©•ä¼°ã€å¯ä¿¡åº¦åˆ†ç´š'
            },
            'trend_analysis': {
                'name': 'ğŸ“ˆ è¶¨å‹¢åˆ†æé æ¸¬',
                'description': 'è¶¨å‹¢è­˜åˆ¥å’Œç™¼å±•æ–¹å‘åˆ†æï¼ŒåŒ…å«æ©Ÿæœƒé¢¨éšªè©•ä¼°',
                'suitable_for': 'å¸‚å ´åˆ†æã€æŠ•è³‡æ±ºç­–ã€ç­–ç•¥è¦åŠƒ',
                'output_focus': 'è¶¨å‹¢è­˜åˆ¥ã€ç™¼å±•é æ¸¬ã€ç­–ç•¥å»ºè­°'
            },
            'future_prediction': {
                'name': 'ğŸš€ æœªä¾†é æ¸¬åˆ†æ',
                'description': 'ç³»çµ±æ€§æœªä¾†é æ¸¬ï¼ŒåŒ…å«å¤šæƒ…å¢ƒå»ºæ¨¡å’Œæ™‚é–“ç·šåˆ†æ',
                'suitable_for': 'æˆ°ç•¥è¦åŠƒã€é¢¨éšªç®¡ç†ã€æ±ºç­–æ”¯æŒ',
                'output_focus': 'æƒ…å¢ƒå»ºæ¨¡ã€æ™‚é–“ç·šé æ¸¬ã€è¡Œå‹•å»ºè­°'
            },
            'industry_insight': {
                'name': 'ğŸ¢ è¡Œæ¥­æ´å¯Ÿåˆ†æ',
                'description': 'å°ˆæ¥­è¡Œæ¥­è§’åº¦æ·±åº¦è§£æï¼ŒåŒ…å«å¸‚å ´ç’°å¢ƒå’Œå•†æ¥­æ¨¡å¼',
                'suitable_for': 'æŠ•è³‡åˆ†æã€å•†æ¥­æ±ºç­–ã€è¡Œæ¥­ç ”ç©¶',
                'output_focus': 'è¡Œæ¥­å®šä½ã€å¸‚å ´åˆ†æã€æŠ•è³‡å»ºè­°'
            },
            'fact_check': {
                'name': 'âœ… äº‹å¯¦æ ¸æŸ¥å ±å‘Š',
                'description': 'ç³»çµ±æ€§äº‹å¯¦æ ¸æŸ¥ï¼ŒåŒ…å«è²æ˜åˆ†é¡å’Œè­‰æ“šè©•ä¼°',
                'suitable_for': 'è³‡è¨Šé©—è­‰ã€æ–°èæ ¸æŸ¥ã€å­¸è¡“ç ”ç©¶',
                'output_focus': 'äº‹å¯¦é©—è­‰ã€ä¾†æºè©•ä¼°ã€å¯ä¿¡åº¦è©•ç´š'
            }
        }
    
    def display_prompt_types_menu(self) -> str:
        """
        é¡¯ç¤º Prompt é¡å‹é¸æ“‡èœå–®
        
        Returns:
            ç”¨æˆ¶é¸æ“‡çš„ prompt é¡å‹
        """
        prompt_types = self.get_available_prompt_types()
        
        print("\nğŸ¯ è«‹é¸æ“‡ AI åˆ†æé¡å‹:")
        print("=" * 80)
        
        type_mapping = {}
        counter = 1
        
        for key, info in prompt_types.items():
            type_mapping[str(counter)] = key
            print(f"{counter:2d}. {info['name']}")
            print(f"    ğŸ“‹ {info['description']}")
            print(f"    ğŸ¯ é©ç”¨å ´æ™¯: {info['suitable_for']}")
            print(f"    ğŸ“Š åˆ†æé‡é»: {info['output_focus']}")
            print()
            counter += 1
        
        print("=" * 80)
        
        while True:
            choice = input(f"è«‹é¸æ“‡åˆ†æé¡å‹ (1-{len(prompt_types)}): ").strip()
            
            if choice in type_mapping:
                selected_type = type_mapping[choice]
                selected_info = prompt_types[selected_type]
                print(f"\nâœ… å·²é¸æ“‡: {selected_info['name']}")
                print(f"ğŸ“ èªªæ˜: {selected_info['description']}")
                return selected_type
            else:
                print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
    
    def analyze_text(self, text: str) -> Dict:
        """
        æ­¥é©Ÿ 10: åŸºæœ¬æ–‡å­—åˆ†æ
        
        Args:
            text: è¦åˆ†æçš„æ–‡å­—
            
        Returns:
            åˆ†æçµæœå­—å…¸
        """
        logger.info("é€²è¡Œæ–‡å­—åˆ†æ")
        
        # åŸºæœ¬çµ±è¨ˆ
        word_count = len(text.split())
        char_count = len(text)
        char_count_no_spaces = len(text.replace(' ', ''))
        
        # å¥å­æ•¸é‡
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text)
        sentence_count = len([s for s in sentences if s.strip()])
        
        # æ®µè½æ•¸é‡
        paragraphs = text.split('\n')
        paragraph_count = len([p for p in paragraphs if p.strip()])
        
        # å¸¸ç”¨è©åˆ†æï¼ˆç°¡å–®å¯¦ç¾ï¼‰
        words = re.findall(r'\b\w+\b', text.lower())
        word_freq = {}
        for word in words:
            if len(word) > 1:  # å¿½ç•¥å–®å­—ç¬¦
                word_freq[word] = word_freq.get(word, 0) + 1
        
        # å–å‰10å€‹æœ€å¸¸ç”¨è©
        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
        
        analysis = {
            'word_count': word_count,
            'character_count': char_count,
            'character_count_no_spaces': char_count_no_spaces,
            'sentence_count': sentence_count,
            'paragraph_count': paragraph_count,
            'top_words': top_words,
            'avg_words_per_sentence': round(word_count / sentence_count, 2) if sentence_count > 0 else 0
        }
        
        logger.info("æ–‡å­—åˆ†æå®Œæˆ")
        return analysis
    
    def process_video(self, video_url: str, output_filename: str = None, 
                     language_codes: List[str] = None) -> Dict:
        """
        å®Œæ•´è™•ç†æµç¨‹ï¼šå¾ URL åˆ°æœ€çµ‚æ–‡å­—
        
        Args:
            video_url: YouTube å½±ç‰‡ URL æˆ– ID
            output_filename: è¼¸å‡ºæª”åï¼ˆå¯é¸ï¼‰
            language_codes: åå¥½èªè¨€ä»£ç¢¼
            
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        result = {
            'success': False,
            'video_id': None,
            'captions_available': False,
            'text': '',
            'speakers': {},
            'analysis': {},
            'filename': None
        }
        
        try:
            # æ­¥é©Ÿ 1: æå–å½±ç‰‡ ID
            video_id = self.extract_video_id(video_url)
            if not video_id:
                result['error'] = 'ç„¡æ³•æå–å½±ç‰‡ ID'
                return result
            
            result['video_id'] = video_id
            
            # æ­¥é©Ÿ 2: æª¢æŸ¥å­—å¹•
            has_captions, available_captions = self.check_captions_available(video_id)
            result['captions_available'] = has_captions
            result['available_captions'] = available_captions
            
            if not has_captions:
                result['error'] = 'å½±ç‰‡æ²’æœ‰å¯ç”¨å­—å¹•'
                return result
            
            # æ­¥é©Ÿ 3-4: æå–è½‰éŒ„
            transcript = self.extract_transcript(video_id, language_codes)
            if not transcript:
                result['error'] = 'ç„¡æ³•æå–è½‰éŒ„å…§å®¹'
                return result
            
            # æ­¥é©Ÿ 5: æ¸…ç†æ–‡å­—
            clean_text = self.clean_text(transcript)
            
            # æ­¥é©Ÿ 6: è­˜åˆ¥è¬›è€…
            speakers = self.identify_speakers(transcript)
            result['speakers'] = speakers
            
            # æ­¥é©Ÿ 7: ä¿®æ­£éŒ¯èª¤
            corrected_text = self.correct_transcription_errors(clean_text)
            result['text'] = corrected_text
            
            # æ­¥é©Ÿ 9: å„²å­˜æ–‡å­—
            if output_filename:
                if self.save_text(corrected_text, output_filename):
                    result['filename'] = f"{output_filename}.txt"
            
            # æ­¥é©Ÿ 10: åˆ†ææ–‡å­—
            analysis = self.analyze_text(corrected_text)
            result['analysis'] = analysis
            
            result['success'] = True
            logger.info("å½±ç‰‡è™•ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è™•ç†å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            result['error'] = str(e)
        
        return result

def main():
    """ä¸»ç¨‹åºç¤ºä¾‹"""
    print("YouTube å½±ç‰‡æ–‡å­—æå–å™¨")
    print("=" * 50)
    
    # åˆå§‹åŒ–æå–å™¨
    # å¦‚æœæœ‰ YouTube API é‡‘é‘°ï¼Œå¯ä»¥åœ¨æ­¤è™•è¨­å®š
    extractor = YouTubeTextExtractor()
    
    # è¼¸å…¥å½±ç‰‡ URL æˆ– ID
    video_input = input("è«‹è¼¸å…¥ YouTube å½±ç‰‡ URL æˆ– ID: ").strip()
    if not video_input:
        print("è«‹æä¾›æœ‰æ•ˆçš„ YouTube å½±ç‰‡ URL æˆ– ID")
        return
    
    # è¨­å®šè¼¸å‡ºæª”å
    output_name = input("è«‹è¼¸å…¥è¼¸å‡ºæª”åï¼ˆä¸å«å‰¯æª”åï¼Œç•™ç©ºå‰‡ä¸å„²å­˜ï¼‰: ").strip()
    if not output_name:
        output_name = None
    
    # è™•ç†å½±ç‰‡
    print("\né–‹å§‹è™•ç†å½±ç‰‡...")
    result = extractor.process_video(video_input, output_name)
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "=" * 50)
    if result['success']:
        print(f"âœ… è™•ç†æˆåŠŸï¼")
        print(f"å½±ç‰‡ ID: {result['video_id']}")
        print(f"å­—å¹•å¯ç”¨: {'æ˜¯' if result['captions_available'] else 'å¦'}")
        
        if result['text']:
            print(f"\nğŸ“ æå–çš„æ–‡å­—é•·åº¦: {len(result['text'])} å­—ç¬¦")
            print(f"å‰100å­—ç¬¦é è¦½:")
            print(result['text'][:100] + "..." if len(result['text']) > 100 else result['text'])
        
        if result['speakers'] and len(result['speakers']) > 1:
            print(f"\nğŸ‘¥ è­˜åˆ¥åˆ° {len(result['speakers'])} ä½è¬›è€…:")
            for speaker in result['speakers']:
                print(f"  - {speaker}")
        
        if result['analysis']:
            analysis = result['analysis']
            print(f"\nğŸ“Š æ–‡å­—åˆ†æ:")
            print(f"  è©æ•¸: {analysis['word_count']}")
            print(f"  å­—ç¬¦æ•¸: {analysis['character_count']}")
            print(f"  å¥æ•¸: {analysis['sentence_count']}")
            print(f"  æ®µè½æ•¸: {analysis['paragraph_count']}")
        
        if result.get('filename'):
            print(f"\nğŸ’¾ æ–‡å­—å·²å„²å­˜è‡³: {result['filename']}")
        
    else:
        print(f"âŒ è™•ç†å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    print("\nç¨‹åºåŸ·è¡Œå®Œæˆã€‚")

if __name__ == "__main__":
    import datetime
    main()